{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FacialExpressionTrainer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NUMBART/Face-Emotion-Recognition-System/blob/master/FacialExpressionTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cohvxutzvrxO",
        "colab_type": "text"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COSksiOXvvBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AdpQmd-NUs3",
        "colab_type": "text"
      },
      "source": [
        "**Mounting Google Drive and changing Current Working Directory**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-UDHjdiNFyF",
        "colab_type": "text"
      },
      "source": [
        "*Mounting Google Drive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUNJ5lMnFu_o",
        "colab_type": "code",
        "outputId": "0de0bddd-ff2c-408c-99b3-d17939a4fd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP5FrKFzJ4L6",
        "colab_type": "text"
      },
      "source": [
        "*Function to create directory tree and forced remount*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPAgLkJ9QLbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drive.mount(\"/content/drive\", force_remount=True)\n",
        "#stackoverflow.com/questions/9727673/list-directory-tree-structure-in-python\n",
        "def list_files(startpath):\n",
        "    for root, dirs, files in os.walk(startpath):\n",
        "        level = root.replace(startpath, '').count(os.sep)\n",
        "        indent = ' ' * 4 * (level)\n",
        "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "        subindent = ' ' * 4 * (level + 1)\n",
        "        for f in files:\n",
        "            print('{}{}'.format(subindent, f))\n",
        "list_files('/content/drive/My Drive/dataset/face-expression-recognition-dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq9qJaC9M2F-",
        "colab_type": "text"
      },
      "source": [
        "*Setting CWD*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9tEew08MSj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/dataset/face-expression-recognition-dataset')\n",
        "cwd = os.getcwd()\n",
        "files = os.listdir(cwd)  # Get all the files in that directory\n",
        "print(\"Files in %r: %s\" % (cwd, files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH7moFEY4GIB",
        "colab_type": "text"
      },
      "source": [
        "**Setting Paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI4Vtdfh3FaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'images/train'\n",
        "#test_path = 'images/test'\n",
        "validation_path = 'images/validation'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJVUSPOg45iJ",
        "colab_type": "text"
      },
      "source": [
        "**Creating validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaInm2k97VeB",
        "colab_type": "code",
        "outputId": "a0dfb3f8-d5cc-4747-d701-fde2300ffa92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "source1 = train_path\n",
        "dest11 = \"Dataset/validation\"\n",
        "files = os.listdir(source1)\n",
        "print(files)\n",
        "import shutil\n",
        "import numpy as np\n",
        "#iterating through classes in \"train\" directory if \"Dataset/validation\" doesn't exist\n",
        "if not os.path.exists(dest11):\n",
        "    for f in files:\n",
        "        source_class_path =  source1 + '/' + f\n",
        "        if os.path.isdir(source_class_path):\n",
        "            class1 = os.listdir(source_class_path)\n",
        "            #iterating through images in each class\n",
        "            for img in class1:\n",
        "                #using a 15/85 split on validation to training data\n",
        "                if np.random.rand(1) < 0.22:\n",
        "                    source_img_path = source1 + '/'+ f + '/' + img\n",
        "                    dest_img_path = dest11 + '/' + f + '/' + img\n",
        "                    dest_class_path = dest11 + '/' + f\n",
        "                    if os.path.isfile(source_img_path):\n",
        "                        if(os.path.exists(dest_class_path)):\n",
        "                            shutil.move(source_img_path, dest_img_path)\n",
        "                        #creating validation and class directories to store images\n",
        "                        else:\n",
        "                            os.makedirs(dest_class_path)\n",
        "                            shutil.move(source_img_path, dest_img_path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsource1 = train_path\\ndest11 = \"Dataset/validation\"\\nfiles = os.listdir(source1)\\nprint(files)\\nimport shutil\\nimport numpy as np\\n#iterating through classes in \"train\" directory if \"Dataset/validation\" doesn\\'t exist\\nif not os.path.exists(dest11):\\n    for f in files:\\n        source_class_path =  source1 + \\'/\\' + f\\n        if os.path.isdir(source_class_path):\\n            class1 = os.listdir(source_class_path)\\n            #iterating through images in each class\\n            for img in class1:\\n                #using a 15/85 split on validation to training data\\n                if np.random.rand(1) < 0.22:\\n                    source_img_path = source1 + \\'/\\'+ f + \\'/\\' + img\\n                    dest_img_path = dest11 + \\'/\\' + f + \\'/\\' + img\\n                    dest_class_path = dest11 + \\'/\\' + f\\n                    if os.path.isfile(source_img_path):\\n                        if(os.path.exists(dest_class_path)):\\n                            shutil.move(source_img_path, dest_img_path)\\n                        #creating validation and class directories to store images\\n                        else:\\n                            os.makedirs(dest_class_path)\\n                            shutil.move(source_img_path, dest_img_path)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9I-fiS5PpQq",
        "colab_type": "code",
        "outputId": "a87f8a48-7eb0-45cd-f186-e1298f98e9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "files = os.listdir(dest11)\n",
        "print(files)\n",
        "list_files(cwd)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfiles = os.listdir(dest11)\\nprint(files)\\nlist_files(cwd)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CQ7NlOuAY-M",
        "colab_type": "text"
      },
      "source": [
        "**Creating batches**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b7jQKoNAfhw",
        "colab_type": "code",
        "outputId": "43c1c7f8-4f1a-43ac-a4f4-ea679946b89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size = (64, 64), color_mode = 'grayscale', classes = ['angry', 'happy', 'sad', 'surprise'], batch_size = 64)\n",
        "validation_batches = ImageDataGenerator().flow_from_directory(validation_path, target_size = (64, 64), color_mode = 'grayscale', classes = ['angry', 'happy', 'sad', 'surprise'], batch_size = 64)\n",
        "#test_batches = ImageDataGenerator().flow_from_directory('Dataset', target_size = (64, 64), color_mode = 'grayscale', classes = ['test'], batch_size = 30, shuffle = 'False')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19310 images belonging to 4 classes.\n",
            "Found 4721 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGM_UGd-I7Hz",
        "colab_type": "text"
      },
      "source": [
        "**Checking batches by plotting images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ltK8Vw7Hi8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plots images with labels within jupyter notebook\n",
        "#https://github.com/smileservices/keras_utils/blob/master/utils.py#L6\n",
        "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeQv2A4mI5wR",
        "colab_type": "code",
        "outputId": "17c866fa-1598-4ffb-9bb1-fa606ac14e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "imgs, labels  = next(train_batches)\n",
        "print(next(train_batches))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimgs, labels  = next(train_batches)\\nprint(next(train_batches))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkp8khVwJijP",
        "colab_type": "code",
        "outputId": "04be53a5-e36d-447f-cf3c-fd8e91da4d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "plots(imgs, figsize = (60,50), titles = labels)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nplots(imgs, figsize = (60,50), titles = labels)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZgcAXlAZrsN",
        "colab_type": "text"
      },
      "source": [
        "**Build and Train CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnGVB9wLZxwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(24, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (64,64,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(24, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(24,kernel_size=5,strides=3,padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(48, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(48, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(48, kernel_size=5, strides=3, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(84, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(84, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(84, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(96, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(4, activation = 'softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwjtLndUeNKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vezWl7wGcKun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(Adam(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBqHyflZc_D6",
        "colab_type": "code",
        "outputId": "7b874287-49c8-49e3-fe51-959e67d8af7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "model.fit_generator(train_batches, steps_per_epoch = 150, validation_data = validation_batches, validation_steps = 36, epochs = 10, use_multiprocessing=True,\n",
        "  workers=16, verbose = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 16s - loss: 0.2017 - acc: 0.9267 - val_loss: 0.8586 - val_acc: 0.7739\n",
            "Epoch 2/10\n",
            " - 13s - loss: 0.2283 - acc: 0.9190 - val_loss: 0.9780 - val_acc: 0.7548\n",
            "Epoch 3/10\n",
            " - 16s - loss: 0.2044 - acc: 0.9253 - val_loss: 0.8752 - val_acc: 0.7724\n",
            "Epoch 4/10\n",
            " - 13s - loss: 0.2163 - acc: 0.9250 - val_loss: 0.9718 - val_acc: 0.7509\n",
            "Epoch 5/10\n",
            " - 16s - loss: 0.1882 - acc: 0.9321 - val_loss: 0.9182 - val_acc: 0.7466\n",
            "Epoch 6/10\n",
            " - 14s - loss: 0.2178 - acc: 0.9190 - val_loss: 0.8849 - val_acc: 0.7613\n",
            "Epoch 7/10\n",
            " - 16s - loss: 0.1904 - acc: 0.9318 - val_loss: 0.8694 - val_acc: 0.7650\n",
            "Epoch 8/10\n",
            " - 14s - loss: 0.2118 - acc: 0.9242 - val_loss: 0.8712 - val_acc: 0.7691\n",
            "Epoch 9/10\n",
            " - 16s - loss: 0.1792 - acc: 0.9358 - val_loss: 0.9643 - val_acc: 0.7540\n",
            "Epoch 10/10\n",
            " - 14s - loss: 0.1924 - acc: 0.9289 - val_loss: 0.8747 - val_acc: 0.7552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f630dc0e9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lASt24NLWuC-",
        "colab_type": "text"
      },
      "source": [
        "**Saving Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAGteRCBXAxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('FacialExpressionRecogniser01.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTX-3L33XspZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = load_model('FacialExpressionRecogniser01.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z-jzraInI3C",
        "colab_type": "text"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bJ6oq86Qv0m",
        "colab_type": "code",
        "outputId": "828af47d-caa5-478c-b4cb-3072bf3d4816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "plot_imgs, plot_labels  = next(test_batches)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nplot_imgs, plot_labels  = next(test_batches)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alyr9X8lwm6s",
        "colab_type": "code",
        "outputId": "6847b2be-6c94-41b4-d244-85fe3d3cdaaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "predictions = model.predict_generator(test_batches, steps = 1, workers = 1, verbose = 0)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\npredictions = model.predict_generator(test_batches, steps = 1, workers = 1, verbose = 0)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYDXCuZWoPqP",
        "colab_type": "code",
        "outputId": "53765b2a-9b83-4319-d36b-84f9b5c517ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "predictions = np.argmax(predictions,axis=1) + 1\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\npredictions = np.argmax(predictions,axis=1) + 1\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZjUDhWGvlRN",
        "colab_type": "code",
        "outputId": "cec95344-a24c-4a20-e6ac-1fda391892fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "print(predictions)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(predictions)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGfwsyShjEMR",
        "colab_type": "code",
        "outputId": "1d46ec84-64f6-47ca-f509-9492e855eccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "plots(plot_imgs, figsize = (20,20), titles = predictions)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nplots(plot_imgs, figsize = (20,20), titles = predictions)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}